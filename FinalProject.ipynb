{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Need to Get the Airport Location NY_Airport_Data [Done]\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from lat_lon_parser import parse\n",
    "import folium as fd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "airport_df = pd.read_csv(r'NY_Airport_Data.csv')\n",
    "airport_df = airport_df[['ref_point_lat','ref_point_lon','objectid','fac_type','loc_id','region_code','state_name','county','fac_name']]\n",
    "airport_df = airport_df[airport_df.fac_type == 'AIRPORT']\n",
    "airport_df = airport_df.reset_index(drop=True)\n",
    "\n",
    "def calculate_lat(row):\n",
    "    val = parse(row['ref_point_lat'])\n",
    "    return val\n",
    "def calculate_lon(row):\n",
    "    val = parse(row['ref_point_lon'])\n",
    "    return val\n",
    "\n",
    "airport_df['lat'] = (airport_df.apply(calculate_lat, axis=1)).round(2)\n",
    "airport_df['lon'] = (airport_df.apply(calculate_lon, axis=1)).round(3)\n",
    "airport_df = airport_df.reset_index(drop=True)\n",
    "# v = parse(\"41-13-51.7000N\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "for i in range(104,367):\n",
    "\n",
    "    netcdf_file_name = './data/windData/' + str(i) + '.nc4'\n",
    "    csv_file_out = './data/windCSV/' + str(i) + '.csv'\n",
    "\n",
    "    ds = xr.open_dataset(netcdf_file_name)\n",
    "    df = ds.to_dataframe()\n",
    "    print(df.describe())\n",
    "    df.to_csv(csv_file_out)\n",
    "\n",
    "    windspeed_df = pd.read_csv(csv_file_out)\n",
    "    windspeed_df = pd.DataFrame(windspeed_df)\n",
    "\n",
    "    windspeed_df = windspeed_df[['lat','lon','U50M','V50M','time']]\n",
    "    windspeed_df['lat'] = windspeed_df['lat'].round(2)\n",
    "    windspeed_df['lon'] = windspeed_df['lon'].round(2)\n",
    "    windspeed_df['date'] = pd.to_datetime(windspeed_df['time']).dt.date\n",
    "\n",
    "    csv_file_out_processed = './data/windCSV/' + str(i) + \"_final.csv\"\n",
    "    windspeed_df.to_csv(csv_file_out_processed)\n",
    "    os.remove(csv_file_out)\n",
    "\n",
    "\n",
    "    # Compute the wind speed for the NewYork State on daily basis.....\n",
    "\n",
    "    windspeed_df = pd.read_csv(csv_file_out_processed)\n",
    "    windspeed_df = pd.DataFrame(windspeed_df)\n",
    "\n",
    "    lon = windspeed_df['lon']\n",
    "    lat = windspeed_df['lat']\n",
    "    date = windspeed_df['date']\n",
    "\n",
    "    # 2-meter eastward wind m/s\n",
    "    U50M = windspeed_df['U50M']\n",
    "    # 2-meter northward wind m/s\n",
    "    V50M = windspeed_df['V50M']\n",
    "\n",
    "    # Replace _FillValues with NaNs:df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    U2M_nans = U50M[:].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    V2M_nans = V50M[:].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # Calculate wind speed:\n",
    "    ws = np.sqrt(U2M_nans**2+V2M_nans**2)\n",
    "    list_s = [lat, lon, date]\n",
    "\n",
    "    new_df = pd.concat(list_s, axis=1)\n",
    "    new_df['avg_windspeed'] = ws\n",
    "    print(new_df.columns)\n",
    "    new_df = pd.DataFrame(new_df.groupby(['lat','lon']).mean()).reset_index()\n",
    "    new_df['date'] = date\n",
    "    new_df.to_csv(csv_file_out_processed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blocks(csv_file_out):\n",
    "    ws_df = pd.read_csv(csv_file_out)\n",
    "    ws_df = pd.DataFrame(ws_df)\n",
    "\n",
    "    _blocks = {\n",
    "        'lower_left_lat': [],\n",
    "        'lower_left_lon': [],\n",
    "        'upper_right_lat': [],\n",
    "        'upper_right_lon': [],\n",
    "        'avg_speed': [],\n",
    "        'date': [],\n",
    "\n",
    "    }\n",
    "    # retrieve lat lon list\n",
    "    lat_list = sorted(set(ws_df['lat'].tolist()))\n",
    "    lon_list = sorted(set(ws_df['lon'].tolist()))\n",
    "    date_list = (set(ws_df['date'].tolist()))\n",
    "    # for loop to generate all blocks\n",
    "    # todo change 'avg windspeed' to wind speed\n",
    "    speed = 0\n",
    "    for x in range(len(lat_list) - 1):\n",
    "        for y in range(len(lon_list) - 1):\n",
    "            speed += ws_df[\n",
    "                (ws_df['lat'] == lat_list[x]) &\n",
    "                (ws_df['lon'] == lon_list[y])]['avg_windspeed'].tolist()[0]\n",
    "            speed += ws_df[\n",
    "                (ws_df['lat'] == lat_list[x + 1]) &\n",
    "                (ws_df['lon'] == lon_list[y])]['avg_windspeed'].tolist()[0]\n",
    "            speed += ws_df[\n",
    "                (ws_df['lat'] == lat_list[x]) &\n",
    "                (ws_df['lon'] == lon_list[y + 1])]['avg_windspeed'].tolist()[0]\n",
    "            speed += ws_df[\n",
    "                (ws_df['lat'] == lat_list[x + 1]) &\n",
    "                (ws_df['lon'] == lon_list[y + 1])]['avg_windspeed'].tolist()[0]\n",
    "\n",
    "            speed = speed / 4\n",
    "            _blocks['lower_left_lat'].append(lat_list[x])\n",
    "            _blocks['upper_right_lat'].append(lat_list[x + 1])\n",
    "            _blocks['lower_left_lon'].append(lon_list[y])\n",
    "            _blocks['upper_right_lon'].append(lon_list[y + 1])\n",
    "            _blocks['avg_speed'].append(speed)\n",
    "            _blocks['date'].append(ws_df.loc[x,'date'])\n",
    "            speed = 0\n",
    "        \n",
    "        \n",
    "    blocks = pd.DataFrame(_blocks)\n",
    "    blocks.to_csv(csv_file_out)\n",
    "\n",
    "\n",
    "for i in range(1,367):\n",
    "    if(i==103): continue;\n",
    "    csv_file_out = './data/windCSV/' + str(i) + '_final.csv'\n",
    "    blocks = generate_blocks(csv_file_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data sets [Issues encountered]\n",
    "def calculate_airport_avg_windspeed(airport_df, blocks):\n",
    "\n",
    "    for row_id, row in airport_df.iterrows():\n",
    "        lat_val = row.lat\n",
    "        lon_val = row.lon\n",
    "        filter1_a = lat_val >= blocks['lower_left_lat']\n",
    "        filter1_b = lat_val <= blocks['upper_right_lat']\n",
    "        filter2_a = lon_val >= blocks['lower_left_lon']\n",
    "        filter2_b = lon_val <= blocks['upper_right_lon']\n",
    "        \n",
    "        calc_time = blocks[(filter1_a) & (filter1_b) & (filter2_a) & (filter2_b)].date.tolist()[0]\n",
    "        calc_speed_temp = round(blocks[(filter1_a) & (filter1_b) & (filter2_a) & (filter2_b)].avg_speed.tolist()[0], 3)\n",
    "        (airport_df.at[row_id, calc_time]) = calc_speed_temp\n",
    "    \n",
    "    return airport_df\n",
    "\n",
    "\n",
    "\n",
    "airport_df_temp = airport_df.copy()\n",
    "for i in range(1,367):\n",
    "    if(i==103): continue;\n",
    "    csv_file_out = './data/windCSV/' + str(i) + '_final.csv'\n",
    "    blocks_ = pd.read_csv(csv_file_out)\n",
    "    blocks_ = pd.DataFrame(blocks_)\n",
    "    print(i)\n",
    "    airport_df_temp = calculate_airport_avg_windspeed(airport_df_temp, blocks_)\n",
    "    \n",
    "final_dataset_with_speed_and_airport = airport_df_temp\n",
    "final_dataset_with_speed_and_airport = final_dataset_with_speed_and_airport.reset_index(drop=True)\n",
    "print(final_dataset_with_speed_and_airport)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "print(len(final_dataset_with_speed_and_airport.columns))\n",
    "temp = final_dataset_with_speed_and_airport.copy()\n",
    "lenght_val = len(temp.columns)\n",
    "temp['Jan'] = 0; temp['Feb'] = 0; temp['Mar'] = 0;temp['Apr'] = 0;temp['May'] = 0;temp['June'] = 0;temp['July'] = 0;temp['Aug'] = 0;temp['Sep'] = 0;temp['Oct'] = 0;temp['Nov'] = 0;temp['Dec'] = 0\n",
    "for cols in temp.columns[11:lenght_val]:\n",
    "    val = pd.to_numeric(cols.split('-')[1]) \n",
    "    if val == 1:\n",
    "        temp['Jan'] += temp[cols]\n",
    "    elif val == 2:\n",
    "        temp['Feb'] += temp[cols]\n",
    "    elif val == 3:\n",
    "        temp['Mar'] += temp[cols]\n",
    "    elif val == 4:\n",
    "        temp['Apr'] += temp[cols]\n",
    "    elif val == 5:\n",
    "        temp['May'] += temp[cols]\n",
    "    elif val == 6:\n",
    "        temp['June'] += temp[cols]\n",
    "    elif val == 7:\n",
    "        temp['July'] += temp[cols]\n",
    "    elif val == 8:\n",
    "        temp['Aug'] += temp[cols]\n",
    "    elif val == 9:\n",
    "        temp['Sep'] += temp[cols]\n",
    "    elif val == 10:\n",
    "        temp['Oct'] += temp[cols]\n",
    "    elif val == 11:\n",
    "        temp['Nov'] += temp[cols]\n",
    "    elif val == 12:\n",
    "        temp['Dec'] += temp[cols]\n",
    "\n",
    "temp = temp.drop(temp.columns[11:lenght_val], axis = 1)\n",
    "final_df_models = temp.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df_models.head())\n",
    "final_df_models.to_csv('./data/windCSV/MonthlyMerged_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Alogs: OPTICS\n",
    "\n",
    "OPTICS clustering (where OPTICS is short for Ordering Points To Identify the Clustering Structure) is a modified version of DBSCAN described above.\n",
    "\n",
    "We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings.\n",
    "\n",
    "— OPTICS: ordering points to identify the clustering structure, 1999.\n",
    "\n",
    "The technique is described in the paper:\n",
    "\n",
    "OPTICS: ordering points to identify the clustering structure, 1999.\n",
    "It is implemented via the OPTICS class and the main configuration to tune is the “eps” and “min_samples” hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "from sklearn.preprocessing import normalize, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the missing values if any\n",
    "\n",
    "airport_dataframe = final_df_models\n",
    "county_list = final_df_models['county'].unique().tolist()\n",
    "\n",
    "airport_dataframe['Category'] = airport_dataframe.county.astype(\"category\").cat.codes\n",
    "airport_dataframe_temp = airport_dataframe[['Jan','Feb','Mar','Apr','May','June','July','Aug','Sep','Oct','Nov','Dec','Category']].copy()\n",
    "temp.to_csv('./data/windData/'+ 'Final_DataSet.csv')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "airport_dataframe_scaled = scaler.fit_transform(airport_dataframe_temp)\n",
    "airport_normalized = normalize(airport_dataframe_scaled)\n",
    "airport_normalized = pd.DataFrame(airport_normalized)\n",
    "airport_normalized.columns = airport_dataframe_temp.columns\n",
    "#print(airport_normalized.head())\n",
    "\n",
    "\n",
    "# Building the OPTICS Clustering model\n",
    "optics_model = OPTICS(min_samples = 50, xi = 0.05, min_cluster_size = 0.05)\n",
    "  \n",
    "# Training the model\n",
    "optics_model.fit_predict(airport_normalized)\n",
    "\n",
    "labels_050 = cluster_optics_dbscan(\n",
    "    reachability=optics_model.reachability_,\n",
    "    core_distances=optics_model.core_distances_,\n",
    "    ordering=optics_model.ordering_,\n",
    "    eps=0.5,\n",
    ")\n",
    "labels_200 = cluster_optics_dbscan(\n",
    "    reachability=optics_model.reachability_,\n",
    "    core_distances=optics_model.core_distances_,\n",
    "    ordering=optics_model.ordering_,\n",
    "    eps=2,\n",
    ")\n",
    "\n",
    "# Storing the cluster labels of each point\n",
    "reachability = optics_model.reachability_[optics_model.ordering_]\n",
    "labels = optics_model.labels_[optics_model.ordering_]\n",
    "space = np.arange(len(airport_normalized))\n",
    "\n",
    "print((labels))\n",
    "print(reachability)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the framework of the visualization\n",
    "plt.figure(figsize =(20, 14))\n",
    "G = gridspec.GridSpec(2, 3)\n",
    "ax1 = plt.subplot(G[0, :])\n",
    "ax2 = plt.subplot(G[1, 0])\n",
    "ax3 = plt.subplot(G[1, 1])\n",
    "ax4 = plt.subplot(G[1, 2])\n",
    "\n",
    "\n",
    "# Reachability plot\n",
    "colors = [\"g.\", \"r.\", \"b.\", \"y.\", \"c.\"]\n",
    "for klass, color in zip(range(0, 5), colors):\n",
    "    Xk = space[labels == klass]\n",
    "    Rk = reachability[labels == klass]\n",
    "    ax1.plot(Xk, Rk, color, alpha=0.3)\n",
    "ax1.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.3)\n",
    "ax1.plot(space, np.full_like(space, 2.0, dtype=float), \"k-\", alpha=0.5)\n",
    "ax1.plot(space, np.full_like(space, 0.5, dtype=float), \"k-.\", alpha=0.5)\n",
    "ax1.set_ylabel(\"Reachability (epsilon distance)\")\n",
    "ax1.set_title(\"Reachability Plot\")\n",
    "\n",
    "\n",
    "# Plotting the OPTICS Clustering\n",
    "colors = ['c.', 'b.', 'r.', 'y.', 'g.']\n",
    "for Class, colour in zip(range(0, 5), colors):\n",
    "    Xk = airport_normalized[optics_model.labels_ == Class]\n",
    "    ax2.plot(Xk.iloc[:, 0], Xk.iloc[:, 1], colour, alpha = 0.3)\n",
    "      \n",
    "ax2.plot(airport_normalized.iloc[optics_model.labels_ == -1, 0],\n",
    "        airport_normalized.iloc[optics_model.labels_ == -1, 1],\n",
    "       'k+', alpha = 0.1)\n",
    "ax2.set_title('OPTICS Clustering')\n",
    "\n",
    "\n",
    "# DBSCAN at 0.5\n",
    "colors = [\"g\", \"greenyellow\", \"olive\", \"r\", \"b\", \"c\"]\n",
    "print('# DBSCAN at 0.5')\n",
    "\n",
    "\n",
    "for i in range(0,11):\n",
    "    for klass, color in zip(range(0, 6), colors):\n",
    "        Xk = airport_normalized[labels_050 == klass]\n",
    "        ax3.plot(Xk[airport_normalized.columns[i]], Xk['Category'], color, alpha=0.3, marker=\".\")\n",
    "\n",
    "\n",
    "# DBSCAN at 2.\n",
    "colors = [\"g.\", \"m.\", \"y.\", \"c.\"]\n",
    "for i in range(0,11):\n",
    "    for klass, color in zip(range(0, 4), colors):\n",
    "        Xk = airport_normalized[labels_200 == klass]\n",
    "        ax4.plot(Xk[airport_normalized.columns[i]], Xk['Category'], color, alpha=0.3)\n",
    "\n",
    "\n",
    "for i in range(0,11):\n",
    "    ax3.plot(airport_normalized.loc[labels_050 == -1, airport_normalized.columns[i]], airport_normalized.loc[labels_050 == -1, 'Category'], \"k+\", alpha=0.1)       \n",
    "    ax4.plot(airport_normalized.loc[labels_200 == -1, airport_normalized.columns[i]], airport_normalized.loc[labels_200 == -1, 'Category'], \"k+\", alpha=0.1)\n",
    "\n",
    "ax3.set_title(\"Clustering at 0.5 epsilon cut\\nDBSCAN\")\n",
    "ax4.set_title(\"Clustering at 2.0 epsilon cut\\nDBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a\n",
    "Kmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. It tries to make the intra-cluster data points as similar as possible while also keeping the clusters as different (far) as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the cluster’s centroid (arithmetic mean of all the data points that belong to that cluster) is at the minimum. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model_dataframe = final_df_models.copy()\n",
    "kmeans_model_dataframe['Category'] = kmeans_model_dataframe.county.astype(\"category\").cat.codes\n",
    "\n",
    "kmeans_model_dataframe = kmeans_model_dataframe[['Jan','Feb','Mar','Apr','May','June','July','Aug','Sep','Oct','Nov','Dec','Category']].copy()\n",
    "kmeans_model_dataframe\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kmeans_model_dataframe_norm = scaler.fit_transform(kmeans_model_dataframe)\n",
    "kmeans_model_dataframe_norm = normalize(kmeans_model_dataframe_norm)\n",
    "kmeans_model_dataframe_norm = pd.DataFrame(kmeans_model_dataframe_norm)\n",
    "kmeans_model_dataframe_norm.columns = kmeans_model_dataframe_norm.columns\n",
    "print(kmeans_model_dataframe_norm.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "inertias = []\n",
    "mapping1 = {}\n",
    "mapping2 = {}\n",
    "K = range(1, 20)\n",
    " \n",
    "for k in K:\n",
    "    # Building and fitting the model\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(kmeans_model_dataframe_norm)\n",
    "    distortions.append(sum(np.min(cdist(kmeans_model_dataframe_norm, kmeanModel.cluster_centers_,\n",
    "                                        'euclidean'), axis=1)) / kmeans_model_dataframe_norm.shape[0])\n",
    "    inertias.append(kmeanModel.inertia_)\n",
    "    mapping1[k] = sum(np.min(cdist(kmeans_model_dataframe_norm, kmeanModel.cluster_centers_,\n",
    "                                   'euclidean'), axis=1)) / kmeans_model_dataframe_norm.shape[0]\n",
    "    mapping2[k] = kmeanModel.inertia_\n",
    "\n",
    "\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(K, inertias, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('The Elbow Method using Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 5)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(kmeans_model_dataframe)\n",
    " \n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "plt.figure(figsize =(20, 7)) \n",
    "for i in u_labels:\n",
    "    plt.scatter(kmeans_model_dataframe.loc[label == i , kmeans_model_dataframe.columns[11]] , kmeans_model_dataframe.loc[label == i , 'Category'] , label = i)\n",
    "\n",
    " \n",
    "plt.legend()\n",
    "plt.xlabel('Values of Avg Windspeed')\n",
    "plt.ylabel('Cluster Labels')\n",
    "plt.title('KMEANS Clustering for NY State for December Month')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize =(20, 7))\n",
    "for i in u_labels:\n",
    "    plt.scatter(kmeans_model_dataframe.loc[label == i , kmeans_model_dataframe.columns[10]] , kmeans_model_dataframe.loc[label == i , 'Category'] , label = i)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Values of Avg Windspeed')\n",
    "plt.ylabel('Cluster Labels')\n",
    "plt.title('KMEANS Clustering for NY State for November Month')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize =(20, 7))\n",
    "for i in u_labels:\n",
    "    plt.scatter(kmeans_model_dataframe.loc[label == i , kmeans_model_dataframe.columns[0]] , kmeans_model_dataframe.loc[label == i , 'Category'] , label = i)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Values of Avg Windspeed')\n",
    "plt.ylabel('Cluster Labels')\n",
    "plt.title('KMEANS Clustering for NY State for January Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Shift Algorithm\n",
    "Mean Shift is a hierarchical clustering algorithm. In contrast to supervised machine learning algorithms, clustering attempts to group data without having first been train on labeled data. Clustering is used in a wide variety of applications such as search engines, academic rankings and medicine. As opposed to K-Means, when using Mean Shift, you don’t need to know the number of categories (clusters) beforehand. The downside to Mean Shift is that it is computationally expensive — O(n²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import MeanShift\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanshift_model_dataframe = final_df_models.copy()\n",
    "meanshift_model_dataframe['Category'] = meanshift_model_dataframe.county.astype(\"category\").cat.codes\n",
    "\n",
    "meanshift_model_dataframe = meanshift_model_dataframe[['Jan','Feb','Mar','Apr','May','June','July','Aug','Sep','Oct','Nov','Dec','Category']].copy()\n",
    "print(meanshift_model_dataframe)\n",
    "\n",
    "ms = MeanShift()\n",
    "ms.fit(meanshift_model_dataframe)\n",
    "cluster_centers = ms.cluster_centers_\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(20, 14))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(meanshift_model_dataframe[meanshift_model_dataframe.columns[0]], meanshift_model_dataframe['Category'], marker='o', color='red')\n",
    "ax.set_xlabel(\"Avergae Windspeed\")\n",
    "ax.set_ylabel(\"Labels\")\n",
    "ax.set_title(\"3D MeanShift Plot for January Month\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize =(20, 14))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(meanshift_model_dataframe[meanshift_model_dataframe.columns[10]], meanshift_model_dataframe['Category'], marker='o', color='green')\n",
    "ax.set_xlabel(\"Avergae Windspeed\")\n",
    "ax.set_ylabel(\"Labels\")\n",
    "ax.set_title(\"3D MeanShift Plot for November Month\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize =(20, 14))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(meanshift_model_dataframe[meanshift_model_dataframe.columns[11]], meanshift_model_dataframe['Category'], marker='o', color='blue')\n",
    "ax.set_xlabel(\"Avergae Windspeed\")\n",
    "ax.set_ylabel(\"Labels\")\n",
    "ax.set_title(\"3D MeanShift Plot for December Month\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
